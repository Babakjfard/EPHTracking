{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth Defects for Nebraska - EPHTracking Fall 2023 Data Call\n",
    "- Babak J.Fard -- October 2023\n",
    "\n",
    "This notebook shows the steps in creating the Birth Defects (BD) datasets-as required by the Tracking How-To-Guide (HTG) and Data Dictionary- from the raw datasets. Since the format of the raw dataset maybe very specific and different from other states (even from the future BD datasets) no separate python code (.py file) is created. The user is suggested to consider the potential differences and changes for use with other datasets. The notebook is reorganized into four sections to be easy to follow.\n",
    "\n",
    "* All cell outputs that may contain detailed level health data are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries for data validation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from libraries import Validator_Nebraska_2023_BirthDefects as VNBD\n",
    "from libraries import general as ge\n",
    "#from pydantic import ValidationError\n",
    "\n",
    "#from itables import init_notebook_mode\n",
    "\n",
    "#init_notebook_mode(all_interactive=True)\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/babak.jfard/projects/EPHTracking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing the Birth Defects Data\n",
    "Using the provided dataset, we have created a validator class. In this step we validate the raw data using Neraska Birth Defect validator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2 = pd.read_csv('Data/BIRTHDEFECTS080823/bd10_9/bd10_9.csv', na_values=['nan'], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the HTG-Appendix A, for BD 27 of CDC/BPA is must exclude 752.61\n",
    "# Since we have CDC/BPA codes before 2015 we replace all these values with ''\n",
    "# to make sure those are excluded\n",
    "bd_2[bd_2['d15'].fillna('').str.startswith('752.621')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For when considering CDC/BPA is used instead of ICD-9, we replace all these values with ''\n",
    "bd_2.loc[bd_2['d15']=='752.621', 'd15'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check\n",
    "bd_2[bd_2['d15'].fillna('').str.startswith('752.621')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the maternal state of residence is NE\n",
    "bd_2.stresm.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping those that maternal state in Nebraska\n",
    "bd_2 = bd_2[bd_2['stresm'].str.lower() == 'nebraska']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the extra column\n",
    "bd_2 = bd_2.drop(columns='stresm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those that birth certificate and fetal death do not match. If fetal_cert is not na, no birth certificate number must be null\n",
    "bd_2[bd_2['fetal_cert'].notna()]['bth_cert1'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing those that the fetal death condition is not null, and  birth certificate is not null too\n",
    "bd_2 = bd_2[~(bd_2['fetal_cert'].notna() & bd_2['bth_cert1'].notna())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a big change between the two datasets. The old one and the new one just provided!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dates\n",
    "reminder from HTG:\n",
    "* A row of data is a unique combination of County, Startdate, Enddate, BirthDefect, MaternalAgeGroup, MaternalRace, and MaternalEthnicity, Infantsex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date columns into datetime format\n",
    "bd_2['dob_c'] = pd.to_datetime(bd_2['dob_c'], format='%m/%d/%Y', errors='coerce')\n",
    "bd_2['dob_m'] = pd.to_datetime(bd_2['dob_m'], format='%m/%d/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2 = bd_2[bd_2['dob_c'].dt.year <= 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maternal Age\n",
    "This section is about the mother's ages and the corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the date of births for mothers are weird. Will change them into NA\n",
    "# bd_2.loc[bd_2['dob_m'].dt.year < 1930].replace('dob_m', pd.NA, inplace=True)\n",
    "bd_2.loc[bd_2['dob_m'].dt.year < 1930, 'dob_m'] = pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if the extracted years from 'dob_c' actually matches those in bthyr column\n",
    "sum(bd_2.dob_c.dt.year.astype('int') - bd_2.bthyr.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2['Mom_Age'] = bd_2['bthyr'].astype('int') - bd_2['dob_m'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2[bd_2['Mom_Age'] <= 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting for these ages\n",
    "bd_2.loc[bd_2['Mom_Age'] <= 12, 'dob_m'] = pd.NA\n",
    "\n",
    "# recalcualting Mom_Age\n",
    "bd_2['Mom_Age'] = bd_2['bthyr'].astype('int') - bd_2['dob_m'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the histogram\n",
    "bd_2['Mom_Age'].hist(bins=10, edgecolor='black')\n",
    "plt.title('Mother Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing ages into MaternalAgeGroup\n",
    "# Categorizing maternal age into the groups from Birth Defects Dictionary, May 2022\n",
    "def categorize_age(df, age_col = 'Mom_Age', new_col= 'MaternalAgeGroup'):\n",
    "    # Define the age categorization function\n",
    "    def age_category(age):\n",
    "        if age < 20:\n",
    "            return 1\n",
    "        elif 20 <= age <= 24:\n",
    "            return 2\n",
    "        elif 25 <= age <= 29:\n",
    "            return 3\n",
    "        elif 30 <= age <= 34:\n",
    "            return 4\n",
    "        elif 35 <= age <= 39:\n",
    "            return 5\n",
    "        elif age >= 40:\n",
    "            return 6\n",
    "        else:\n",
    "            return 9  # Unknown\n",
    "\n",
    "    # Apply the age categorization function to the 'Mom_Age' column\n",
    "    df[new_col] = df[age_col].apply(age_category)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2 = categorize_age(bd_2)\n",
    "# matches = categorize_age(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each category\n",
    "age_counts = bd_2['MaternalAgeGroup'].value_counts()\n",
    "\n",
    "# Sort the index\n",
    "age_counts = age_counts.sort_index()\n",
    "\n",
    "# Plotting the bar plot\n",
    "age_counts.plot(kind='bar', edgecolor='black', align='center')\n",
    "plt.title('Mother Age Category')\n",
    "plt.xlabel('Age Category')\n",
    "plt.ylabel('Number')\n",
    "plt.xticks(rotation=0)  # Ensure x-axis labels are horizontal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County Codes\n",
    "The provided counties are in names format. In this section created a column for their corresponding FIPS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the numeric FIPS code\n",
    "fips = ge.get_Counties_FIPS()\n",
    "fips['county_name'] = fips['county_name'].str.lower()\n",
    "fips['county_name'] = fips['county_name'].str.replace(\" county\", \"\")\n",
    "\n",
    "\n",
    "bd_2['cou'] = bd_2['cou'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2 = bd_2.merge(fips, left_on='cou', right_on='county_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the merge has worked out fine!\n",
    "bd_2[bd_2['cou'] != bd_2['county_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing cou and renaming the new column\n",
    "bd_2 = bd_2.drop(columns=['cou', 'county_name'])\n",
    "bd_2.rename(columns={'fips': 'County', 'sex':'InfantSex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maternal Race and Ethnicity\n",
    "Following HTG one column for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = {1:'W', 2:'B', 3:'O', 4:'O', 8:'O', 9:'U'}\n",
    "ethnicity = {1:'NH', 2:'NH', 3:'NH', 4:'NH', 8: 'H', 9:'U'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2.racethm = bd_2.racethm.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2['MaternalEthnicity'] = bd_2['racethm'].replace(ethnicity)\n",
    "bd_2['MaternalRace'] = bd_2['racethm'].replace(race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2 = bd_2.drop(columns='racethm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2['StartDate'] = bd_2['bthyr'].astype('str')+'0101'\n",
    "bd_2['EndDate'] = bd_2['bthyr'].astype('str')+'1231'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2 = bd_2.drop(columns=['dob_c', 'bthyr', 'dob_m', 'case_id', 'Mom_Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting ICD-9 and ICD-10s to BirthDefect Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Reading ICD-9 codes related to the Birth Defects\n",
    "with open('Data/Dictionaries/BirthDefects_icd_9_convert.json', 'r') as f:\n",
    "     icd_9_dict = json.load(f)\n",
    "\n",
    "# Reading CDC/BPA codes related to the Birth Defects\n",
    "with open('Data/Dictionaries/BirthDefects_CDC_BPA_convert.json', 'r') as f:\n",
    "    icd_BPA_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/Dictionaries/BirthDefects_icd_10_convert.json') as f:\n",
    "    icd_10_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_BPA_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function maps the values of icd_9 or icd_10 into the values of BirthDefect 12 codes\n",
    "# This method was not used\n",
    "# def lookup_icd_value(value, icd_code = 10):\n",
    "#     if icd_code == 10:\n",
    "#         return icd_10_dict.get(value, np.nan)\n",
    "#     if icd_code == 9:\n",
    "#         return icd_9_dict.get(value, np.nan)\n",
    "#     \n",
    "# # Creating a column mapping from ICD-9\n",
    "# bd['BIRTH_DEFECTS_from_9'] = bd['DEFECT_CODE'].apply(lookup_icd_value, icd_code = 9)\n",
    "# bd['BIRTH_DEFECTS_from_10'] = bd['DEFECT_CODE10CM'].apply(lookup_icd_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second method: Instead of the exact match, look if it starts with a key in the dictionary\n",
    "def lookup_icd_value_startsWith(value, icd_code=10):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan\n",
    "    # value = str(value)\n",
    "    if icd_code == 10:\n",
    "        for key in icd_10_dict:\n",
    "            if value.startswith(key):\n",
    "                return icd_10_dict[key]\n",
    "        return np.nan\n",
    "    if icd_code == 9:\n",
    "        for key in icd_9_dict:\n",
    "            if value.startswith(key):\n",
    "                return icd_9_dict[key]\n",
    "        return np.nan\n",
    "    if icd_code == 8:\n",
    "        for key in icd_BPA_dict:\n",
    "            if value.startswith(key):\n",
    "                return icd_BPA_dict[key]\n",
    "    \n",
    "# Creating a column mapping from ICD-9\n",
    "#bd_2['BIRTH_DEFECTS_from_9'] = bd_2['d15'].apply(lookup_icd_value_startsWith, icd_code = 9)\n",
    "bd_2['BIRTH_DEFECTS_from_9'] = bd_2['d15'].apply(lookup_icd_value_startsWith, icd_code = 8)\n",
    "bd_2['BIRTH_DEFECTS_from_10'] = bd_2['d16'].apply(lookup_icd_value_startsWith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birth Defects out of our 12 categories\n",
    "not_matches = bd_2[bd_2['BIRTH_DEFECTS_from_9'].isna() & bd_2['BIRTH_DEFECTS_from_10'].isna()]\n",
    "\n",
    "# Birth Defects of our 12 categories\n",
    "matches = bd_2[bd_2['BIRTH_DEFECTS_from_9'].notna() | bd_2['BIRTH_DEFECTS_from_10'].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what percentages of total birth defects for 2005 to 2021 are from the 12 categories from the Tracking(below shows it's around 6.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.shape[0]* 100 / bd_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the duplicated values that values for both ICD-10 and CDC/BPA result into similar BD ids\n",
    "dup_check = bd_2[bd_2['BIRTH_DEFECTS_from_10'].notna() & bd_2['BIRTH_DEFECTS_from_9'].notna()]\n",
    "sum(dup_check['BIRTH_DEFECTS_from_10'] != dup_check['BIRTH_DEFECTS_from_9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two columns into BirthDefect column\n",
    "def merge_defect_columns(row, ICD_9_Col='BIRTH_DEFECTS_from_9', ICD_10_Col= 'BIRTH_DEFECTS_from_10'):\n",
    "    val_10 = row[ICD_10_Col]\n",
    "    val_9 = row[ICD_9_Col]\n",
    "    \n",
    "    if pd.isna(val_10) and pd.isna(val_9):\n",
    "        return np.nan\n",
    "    elif pd.isna(val_10):\n",
    "        return val_9\n",
    "    elif pd.isna(val_9):\n",
    "        return val_10\n",
    "    else:\n",
    "        return val_10 if val_10 == val_9 else np.nan\n",
    "\n",
    "bd_2['BirthDefects'] = bd_2.apply(merge_defect_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_2['BirthDefects'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final preparations of the Birth Defect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are only interested in `matches` section of data that contains the 12 BDs of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['BirthDefect'] = matches.apply(merge_defect_columns, axis=1)\n",
    "matches['BirthDefect'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.MaternalEthnicity.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.MaternalRace.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of live births with the specified birth defects\n",
    "matches.bth_cert1.notna().sum()*100/matches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of fetal death with the specified birth defects\n",
    "matches.fetal_cert.notna().sum()*100/matches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['BirthDefect', 'County', 'StartDate', 'EndDate','MaternalAgeGroup', 'MaternalEthnicity', 'MaternalRace',\n",
    "                   'InfantSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd_grouped = matches.groupby(group_by).agg(LBWBD=('bth_cert1', 'size')).reset_index()\n",
    "bd_grouped = matches.groupby(group_by).agg(LBWBD=('bth_cert1', lambda x: x.notna().sum()),\n",
    "                                           LBFDTWD=('bth_cert1', 'size')).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_grouped.to_csv('Data/BIRTHDEFECTS080823/BirthDefects_without_TBL_BPA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of this section the following command deletes all the memory.\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Preparing the Live Birth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from libraries import general as ge\n",
    "\n",
    "# from itables import init_notebook_mode\n",
    "\n",
    "#init_notebook_mode(all_interactive=True)\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/babak.jfard/projects/EPHTracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live_births = pd.read_csv('Data/BIRTHDEFECTS080823/Live Births/bth2005.csv')\n",
    "folder = r'Data/BIRTHDEFECTS080823/Live Births'\n",
    "live_births = pd.concat((pd.read_csv(folder+'/'+filename)) for filename in os.listdir(folder) if filename.endswith('.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of live births in each year\")\n",
    "live_births.DOB_YY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those with mother state of residence as NE\n",
    "live_births = live_births[live_births.strm == 'NE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births['coures'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting the FIPS code, Maternal Ethnicity, and Dates\n",
    "received FIPS codes for the counties are in three digit format. needs to be chanded into five digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making FIPS codes into 5 dgigts\n",
    "state_FIPS = '31' #For Nebraska.\n",
    "\n",
    "live_births.coures = live_births.coures.astype('str').str.zfill(3) #Pad strings in the Series/Index by prepending ‘0’ characters.\n",
    "live_births['County'] = (state_FIPS+ live_births['coures']).astype('int')\n",
    "live_births.drop(columns='coures', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births['StartDate'] = live_births['DOB_YY'].astype('str') + '0101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.rename(columns={'sex': 'InfantSex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinguishing Ethnicity\n",
    "# Define the conditions and choices\n",
    "conditions = [\n",
    "    live_births['hispanicm'].str.contains('H'),\n",
    "    live_births['hispanicm'].str.contains('U')\n",
    "]\n",
    "choices = ['H', 'U']\n",
    "\n",
    "# Create the new column using np.select\n",
    "live_births['MaternalEthnicity'] = np.select(conditions, choices, default='NH')\n",
    "live_births = live_births.drop(columns='hispanicm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.MaternalEthnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing maternal age into the groups from the HTG, and saving it into the appropriate column\n",
    "live_births = categorize_age(live_births, age_col='agemo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing Maternal Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_other_columns = ['aindianm', 'chamorrom', 'chinesem', 'filipinom', 'indianm', 'japanesem',\n",
    "                      'koreanm', 'nhawaiianm', 'opacislm', 'otheram', 'otherm', 'samoanm', 'vietnamesem']\n",
    "race_black_columns = 'blackm'\n",
    "race_white_columns = 'whitem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the unique values in all other race columns are 'Y' or 'N'\n",
    "[print(f\"{col}: {live_births[col].value_counts(dropna=False)}\") for col in race_other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing to digist to better be able to check consistency\n",
    "to_digits = {'Y':1, 'N':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[live_births[col].replace(to_digits, inplace=True) for col in race_other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating all into one column for other\n",
    "live_births['race_other'] = live_births[race_other_columns].sum(axis=1)\n",
    "live_births['race_other'] = np.where(live_births['race_other']>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for Black and White races\n",
    "live_births[race_white_columns].replace(to_digits, inplace=True)\n",
    "live_births[race_black_columns].replace(to_digits, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking potential values. In an ideal situation there must be only one\n",
    "# or 0 for unknown\n",
    "three_races = ['blackm', 'whitem', 'race_other']\n",
    "live_births[three_races].sum(axis=1).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well. Looks good. only about 3% are not 1. Now if this value is other than one it will return 'U', otherwise checks which of 'W', 'B' or 'O' applies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the three columns\n",
    "live_births['sum_race'] = live_births[['blackm', 'whitem', 'race_other']].sum(axis=1)\n",
    "\n",
    "# Define the conditions and choices for the 'MaternalRace' column\n",
    "conditions = [\n",
    "    (live_births['sum_race'] != 1),\n",
    "    (live_births['blackm'] == 1),\n",
    "    (live_births['whitem'] == 1),\n",
    "    (live_births['race_other'] == 1)\n",
    "]\n",
    "choices = ['U', 'B', 'W', 'O']\n",
    "\n",
    "# Create the 'MaternalRace' column using numpy.select\n",
    "live_births['MaternalRace'] = np.select(conditions, choices)\n",
    "\n",
    "# Drop the 'sum_race' column as it's no longer needed\n",
    "live_births.drop('sum_race', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.MaternalRace.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up\n",
    "Here we prepare, rename and reorder column to get ready for joining with the birth defects data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['County', 'StartDate', 'MaternalAgeGroup', 'MaternalEthnicity', 'MaternalRace',\n",
    "                   'InfantSex']\n",
    "live_births = live_births[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.StartDate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.to_csv('Data/BIRTHDEFECTS080823/live_births_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now grouping them and calculating TLB\n",
    "#live_births['TLB'] = live_births.groupby(columns_to_keep).transform('size')\n",
    "lb_grouped = live_births.groupby(columns_to_keep).agg(TLB=('County', 'size')).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_grouped.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Total births\n",
    "lb_grouped.to_csv('Data/BIRTHDEFECTS080823/live_births_summarized.csv', index=False)\n",
    "\n",
    "# ****************************** F I N I S H E D (Live Birth data section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Joining the Datasets\n",
    "Here we join the two tables into the final table. But first check to make sure that the key columns actually match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from libraries import general as ge\n",
    "\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/babak.jfard/projects/EPHTracking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_grouped = pd.read_csv('Data/BIRTHDEFECTS080823/BirthDefects_without_TBL_BPA.csv')\n",
    "lb_grouped = pd.read_csv('Data/BIRTHDEFECTS080823/live_births_summarized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the years have all 93 counties\n",
    "lb_grouped.groupby('StartDate')['County'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which county is missing in 20120101?\n",
    "set(lb_grouped.County) - set(lb_grouped[lb_grouped['StartDate']==20120101]['County'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_and_insert_row(df, new_row, key_columns):\n",
    "    \"\"\"\n",
    "    Check if a new row is a duplicate based on key columns and insert it if not.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to check against.\n",
    "    new_row (dict): The new row to insert, in the form of a dictionary.\n",
    "    key_columns (list): The list of columns to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (is_duplicate, df)\n",
    "        is_duplicate (bool): True if the new row is a duplicate, False otherwise.\n",
    "        df (pd.DataFrame): The updated DataFrame with the new row inserted if not a duplicate.\n",
    "    \"\"\"\n",
    "    # Check if the new_row values for key columns match any existing rows\n",
    "    is_duplicate = (df[key_columns] == pd.Series(new_row, index=key_columns)).all(axis=1).any()\n",
    "\n",
    "    if is_duplicate:\n",
    "        print(\"The new row is a duplicate based on the key columns.\")\n",
    "    else:\n",
    "        print(\"The new row is not a duplicate and has been added to the DataFrame.\")\n",
    "        # Add the new row to the DataFrame\n",
    "        #df = df.append(new_row, ignore_index=True)\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "    \n",
    "    return is_duplicate, df\n",
    "\n",
    "# Example usage:\n",
    "# df is your existing DataFrame\n",
    "# new_row is a dictionary with your new row data\n",
    "# key_columns are the columns you want to check for duplicates\n",
    "# is_duplicate, updated_df = check_and_insert_row(df, new_row, key_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new row for 2012\n",
    "new_row = {'County': 31117 , 'StartDate': 20120101, 'MaternalAgeGroup':9, 'MaternalEthnicity': \"U\",\n",
    "       'MaternalRace': \"U\", 'InfantSex': \"U\", 'TLB': 0}\n",
    "key_columns = ['County', 'StartDate', 'MaternalAgeGroup', 'MaternalEthnicity',\n",
    "       'MaternalRace', 'InfantSex']\n",
    "_, lb_grouped = check_and_insert_row(lb_grouped, new_row, key_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again\n",
    "lb_grouped.groupby('StartDate')['County'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key columns to join the live birth and birth defects tables\n",
    "key_cols = ['County', 'StartDate', 'MaternalAgeGroup', 'MaternalEthnicity', 'MaternalRace', 'InfantSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the unique values of key columns in each df befor joining them\n",
    "def comp_col_types(lb_grouped, bd_grouped, key_cols):\n",
    "    lb_cols = lb_grouped[key_cols].dtypes.to_list()\n",
    "    bd_cols = bd_grouped[key_cols].dtypes.to_list()\n",
    "\n",
    "    if lb_cols == bd_cols:\n",
    "        print(\"Columns match. We're good to go!\")\n",
    "    else:\n",
    "        print(\"There are some mismatches between key columns\")\n",
    "        print(key_cols)\n",
    "        print(f\"Birth Defects: {bd_cols}\")\n",
    "        print(f\"Live Births: {lb_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_col_types(lb_grouped, bd_grouped, key_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the differences in the unique values for corresponding columns\n",
    "for col in key_cols:\n",
    "    values_bd = set(bd_grouped[col])\n",
    "    values_lb = set(lb_grouped[col])\n",
    "    \n",
    "    unique_to_bd = values_bd - values_lb\n",
    "    unique_to_lb = values_lb - values_bd\n",
    "    \n",
    "    print(f\"Values in {col} unique to Birth Defects: {unique_to_bd}\")\n",
    "    print(f\"Values in {col} unique to Live Births: {unique_to_lb}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer join between Birth Defects and Live Births\n",
    "We will have all counties present in each year. But LBWBD and LBFDTWD values for many cases will be 0 because there is no Birth Defect in such cases. It will require an outer join method. Also, each birth defct when added for TLBs must add up into total live births. Therefore, we separate BD data for each BirthDefect, do outer join and in the end concatenate all the resulted 12 tables into one final table\n",
    "\n",
    "***Note:*** to make sure that the denominator for each Birth Defect is the total live birth, data for each birth defect is separated and is outer joined with the live birth data, and in the end all the separate 12 joined tables are concatenated into the final dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two datasets\n",
    "all_bds = []  # Create an empty list to store the dataframes\n",
    "\n",
    "# Loop over unique values of 'BirthDefects' column in bd_grouped\n",
    "for defect in bd_grouped['BirthDefect'].unique():\n",
    "    # Separate rows with the current 'BirthDefects' value\n",
    "    current_defect_df = bd_grouped[bd_grouped['BirthDefect'] == defect]\n",
    "    \n",
    "    # Perform the outer join with lb_grouped on key columns\n",
    "    merged_df = lb_grouped.merge(current_defect_df, on=key_cols, how='outer')\n",
    "    \n",
    "    # For unassigned 'BirthDefects', change them to the current 'BirthDefect' value\n",
    "    merged_df['BirthDefect'].fillna(defect, inplace=True)\n",
    "    \n",
    "    # Add the new dataframe to the 'all_bds' list\n",
    "    all_bds.append(merged_df)\n",
    "\n",
    "# Continue the loop for the next 'BirthDefect'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd = pd.concat(all_bds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next step will be to take care of Nan values for non-matched rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) TLB: TLB is for those cases that we have maternal age 9. This is exactly the same number as we had in the first approach. Therefore we set them to -999\n",
    "2) BirthDefect: For cases that we only want to provide live births. We add 21\n",
    "3) EndDate = (StartDate // 1e4)* 1e4 + 1231\n",
    "4) LBWBD will be 0 for all missing values\n",
    "5) LBFDTWD same as LBWBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd['TLB'].fillna(-999, inplace=True)\n",
    "final_bd['EndDate'] = (final_bd['StartDate'] // 1e4) * 1e4 + 1231\n",
    "final_bd['LBWBD'].fillna(0, inplace=True)\n",
    "final_bd['LBFDTWD'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toSave = final_bd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: Prepare Data to Save\n",
    "This is the final step to save data into format and numbers that can be submitted to the Tracking system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the columns in the same order as Data Dictionary\n",
    "ordered_columns = ['County', 'StartDate', 'EndDate', 'BirthDefect', 'MaternalAgeGroup',\n",
    "                   'MaternalEthnicity', 'MaternalRace', 'InfantSex', 'TLB', 'LBWBD', 'LBFDTWD']\n",
    "\n",
    "data_toSave = data_toSave[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types\n",
    "data_toSave.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_int = ['EndDate', 'BirthDefect', 'TLB', 'LBWBD', 'LBFDTWD']\n",
    "data_toSave[cols_to_int] = data_toSave[cols_to_int].astype('int')\n",
    "\n",
    "data_toSave.InfantSex.replace({'N': 'U'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check\n",
    "for i in range(8):\n",
    "    col = data_toSave.columns[i]\n",
    "    print(f'Column: {col}')\n",
    "    print(data_toSave[col].unique())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now saving each year into a separate file:\n",
    "#output_folder = 'Data/BIRTHDEFECTS080823/To_Submit/'\n",
    "output_folder = 'Data/BIRTHDEFECTS080823/final_submit/'\n",
    "\n",
    "for st_date in data_toSave.StartDate.unique():\n",
    "    to_save = data_toSave[data_toSave['StartDate'] == st_date]\n",
    "    to_save.index = range(1, len(to_save) + 1)\n",
    "    year = (st_date//1e4).astype('int').astype('str')\n",
    "    filename = output_folder+'BirthDefects_AllCounties_'+year+ '.csv'\n",
    "\n",
    "    to_save.to_csv(filename, index = True,index_label='RowIdentifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Some Checks\n",
    "Some checks to make sure the data makes sense\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking if the sum of TLBs for each BirthDefect adds up to total live births in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ignore_values(series, ignore=-999):\n",
    "    return series.replace(ignore, np.nan).sum()\n",
    "\n",
    "data_toSave.pivot_table(index='StartDate', columns='BirthDefect', values='TLB', aggfunc=lambda x: sum_ignore_values(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plotting the Sum, max, mean, min for each Birth Defect in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_summaries(df, groups, coexist, x_column, nrow):\n",
    "    # Get unique values from the groups column\n",
    "    unique_groups = df[groups].unique()\n",
    "    \n",
    "    # Calculate number of columns for the grid\n",
    "    ncol = len(unique_groups) // nrow\n",
    "    if len(unique_groups) % nrow != 0:\n",
    "        ncol += 1\n",
    "    \n",
    "    # Initialize a figure\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(15, 10))\n",
    "    \n",
    "    # If there's only one row or one column, axes is a 1D array\n",
    "    if nrow == 1 or ncol == 1:\n",
    "        axes = axes.reshape(nrow, ncol)\n",
    "    \n",
    "    # Iterate over each unique group and plot\n",
    "    for idx, group in enumerate(unique_groups):\n",
    "        ax = axes[idx // ncol, idx % ncol]\n",
    "        \n",
    "        # Filter dataframe for the current group\n",
    "        subset = df[df[groups] == group]\n",
    "        \n",
    "        # Plot each column in coexist\n",
    "        for col in coexist:\n",
    "            sns.lineplot(data=subset, x=x_column, y=col, ax=ax, label=col)\n",
    "        \n",
    "        ax.set_title(f\"{groups}: {group}\")\n",
    "        ax.legend()\n",
    "    \n",
    "    # If there are empty subplots, hide them\n",
    "    for idx in range(len(unique_groups), nrow * ncol):\n",
    "        axes[idx // ncol, idx % ncol].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_summary = data_toSave.groupby(['BirthDefect', 'StartDate'])['LBFDTWD'].agg(SUM = 'sum', MIN='min', MEAN='mean', MAX='max').reset_index()\n",
    "ds_summary['BirthDefect'] = ds_summary['BirthDefect'].astype('int')\n",
    "ds_summary.StartDate = ds_summary.StartDate.astype('str').str[2:4]\n",
    "\n",
    "plot_summaries(df=ds_summary, groups='BirthDefect', coexist=['SUM', 'MIN', 'MEAN', 'MAX'], x_column='StartDate', nrow=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
