std_map_ggplot <- function(data_column, title="std map"){
sd_dev_colors <- c("#3566A6", "#76A8CB", "#D4E4EF", "#F7DCC9", "#E18E6A", "#A32A30")
year <- names(data_column)[1]
#map_test <- merge(map_2019, data_column, by='GEOID')
#map_test[as.character(year)] <- dat
# map_test['lisa_p'] <- as.factor(lisa_pvalues(lisa))
result <- ggplot(data = data_column)+
geom_sf(aes(fill=!!sym(year)), size=0.2, color="grey")+
scale_fill_manual(values = sd_dev_colors)+
geom_sf(data=state_map, fill=NA, size=0.2, color='black')+
theme_void()+
labs(title = title)+
theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5))
theme(plot.background = element_rect(fill = "white"))
return(result)
}
std_map_ggplot(PM25_annual[,4])
std_cuts <- function(data_column){
st_dev <- stddev_breaks(data_column)
data_column <- unlist(data_column)
# Create the factor column with custom levels
categories <- factor(cut(data_column, breaks = c(-Inf, st_dev, Inf)))
return(categories)
}
tibble_to_cut_std <- function(to_std){
to_std <- to_std%>% ungroup()
done_std <-tibble(GEOID= to_std$GEOID)
to_std <- to_std %>% select(-GEOID)
for (col in colnames(to_std)){
done_std[col] <- std_cuts(to_std[col])
}
return(done_std)
}
a <- std_cuts
a <- std_cuts(PM25_annual[,4])
a
length(a)
data_column <- PM25_annual[,4]
View(data_column)
stddev_breaks(data_column)
View(data_column)
data_column[,1]
cut(data_column[,1], breaks = c(-Inf, std_dev, Inf))
cut(st_drop_geometry(data_column[,1]), breaks = c(-Inf, std_dev, Inf))
data_column <- st_drop_geometry(PM25_annual[,4])
cut(data_column, breaks = c(-Inf, st_dev, Inf))
std_cuts <- function(data_column){
st_dev <- stddev_breaks(data_column)
data_column <- unlist(data_column)
# Create the factor column with custom levels
categories <- factor(cut(data_column, breaks = c(-Inf, st_dev, Inf)))
return(categories)
}
# Create a new dataframe with the same columns as input dataframe
tibble_to_cut_std <- function(to_std){
to_std <- to_std%>% ungroup()
done_std <-tibble(GEOID= to_std$GEOID)
to_std <- to_std %>% select(-GEOID)
for (col in colnames(to_std)){
done_std[col] <- std_cuts(to_std[col])
}
return(done_std)
}
cut(data_column, breaks = st_dev)
std_cuts <- function(data_column){
st_dev <- stddev_breaks(data_column)
data <- unlist(data_column[,1])
# Create the factor column with custom levels
categories <- factor(cut(data, breaks = c(-Inf, st_dev, Inf)))
data_column[,1] <- categories
return(data_column)
}
data_column
data_column <- PM25_annual[,5]
data_column
unlist(data_column[,1])
PM25_stds <- st_drop_geometry(PM25_annual)
std_cuts <- function(data_column){
st_dev <- stddev_breaks(data_column)
data <- unlist(data_column)
# Create the factor column with custom levels
categories <- factor(cut(data, breaks = c(-Inf, st_dev, Inf)))
return(categories)
}
tibble_to_cut_std <- function(to_std){
to_std <- to_std%>% ungroup()
done_std <-tibble(GEOID= to_std$GEOID)
to_std <- to_std %>% select(-GEOID)
for (col in colnames(to_std)){
done_std[col] <- std_cuts(to_std[col])
}
return(done_std)
}
PM25_stds <- tibble_to_cut_std(st_drop_geometry(PM25_annual))
to_std <- st_drop_geometry(PM25_annual)
to_std
tibble_to_cut_std <- function(to_std){
to_std <- to_std%>% ungroup()
done_std <-tibble(GEOID= to_std$GEOID)
to_std <- to_std %>% select(-c(GEOID, NAME))
for (col in colnames(to_std)){
done_std[col] <- std_cuts(to_std[col])
}
return(done_std)
}
PM25_std <- tibble_to_cut_std(st_drop_geometry(PM25_annual))
View(PM25_std)
View(PM25_std)
std_map_ggplot <- function(data_column, title="std map"){
sd_dev_colors <- c("#3566A6", "#76A8CB", "#D4E4EF", "#F7DCC9", "#E18E6A", "#A32A30")
year <- names(data_column)[1]
map_test <- merge(map_2019, data_column, by='GEOID')
#map_test[as.character(year)] <- dat
# map_test['lisa_p'] <- as.factor(lisa_pvalues(lisa))
result <- ggplot(data = map_test)+
geom_sf(aes(fill=!!sym(year)), size=0.2, color="grey")+
scale_fill_manual(values = sd_dev_colors)+
geom_sf(data=state_map, fill=NA, size=0.2, color='black')+
theme_void()+
labs(title = title)+
theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5))
theme(plot.background = element_rect(fill = "white"))
return(result)
}
std_map_ggplot <- function(data_column, title="std map"){
sd_dev_colors <- c("#3566A6", "#76A8CB", "#D4E4EF", "#F7DCC9", "#E18E6A", "#A32A30")
year <- names(data_column)[2]
map_test <- merge(map_2019, data_column, by='GEOID')
#map_test[as.character(year)] <- dat
# map_test['lisa_p'] <- as.factor(lisa_pvalues(lisa))
result <- ggplot(data = map_test)+
geom_sf(aes(fill=!!sym(year)), size=0.2, color="grey")+
scale_fill_manual(values = sd_dev_colors)+
geom_sf(data=state_map, fill=NA, size=0.2, color='black')+
theme_void()+
labs(title = title)+
theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5))
theme(plot.background = element_rect(fill = "white"))
return(result)
}
PM25_std[, c('GEOID', 2)]
std_map_ggplot(PM25_std[,c(1,5)])
std_map_ggplot(PM25_std[,c(1,5)], title = 'PM2.5')
View(PM25_annual)
View(PM25_annual)
library(tidyverse)
library(sf)
library(lubridate)
library(rlang)
library(ggplot2)
library(gridExtra)
library(tsibble)
library(tidycensus)
variables <- c("B01003_001E")
population <- get_acs(geography = "county", variables = variables, geometry = FALSE, year = 2013)  #paste0("B01001_0",20:25,"E")
highest_averaged_values <- function(the_data, column_name, n=100, highest=TRUE){
highest_n <- the_data %>%
group_by(GEOID, year) %>%
summarise(average = mean(!!sym(column_name))) %>%
group_by(GEOID) %>%
summarise(average = mean(average)) %>%
arrange(desc(average))
if (highest) {
highest_n <- highest_n %>% slice_max(order_by = average, n = n)
} else {
highest_n <- highest_n %>% slice_min(order_by = average, n = n)
}
return(highest_n)
}
# the plot of the values on top of a state map
map_of_available_values <- function(map, thedata, the_variable, fill_low='blue', fill_high='grey'){
state_map <- st_read('/Users/babak.jfard/Documents/ArcGIS/cb_2018_us_state_20m_CONUS/cb_2018_us_state_20m.shp')
data_map <- merge(map, thedata, by='GEOID', all.y=TRUE)
result <- ggplot()+
geom_sf(data = data_map, aes(fill=!!sym(the_variable)), color=NA)+
scale_fill_gradient(low = fill_low, high = fill_high)+
geom_sf(data = map, fill=NA, size=0.1, color='#B2BEB5')+
geom_sf(data=state_map, fill=NA, size=0.1, color='black')+
theme_void()+
#theme(plot.title = element_text(size=22))+
theme(strip.text.x = element_text(size = 14))+
theme(legend.key.size = unit(1, 'cm'))
}
add_date_column <- function(df, year_column='year', month_column='month') {
df <- df %>%
mutate(date = make_date(!!sym(year_column), !!sym(month_column)))
return(df)
}
plot_average_with_confidence <- function(data, date_column, value_column, show_all_years = FALSE) {
# Calculate the average and confidence interval for the specified value column by date
average_data <- data %>%
group_by(!!sym(date_column)) %>%
summarise(average = mean(!!sym(value_column), na.rm = TRUE),
lower = quantile(!!sym(value_column), 0.025, na.rm = TRUE),
upper = quantile(!!sym(value_column), 0.975, na.rm = TRUE))
# Plot the line plot with average and confidence interval
ggplot(average_data, aes(x = !!sym(date_column), y = average)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), fill = "gray70", alpha = 0.3) +
labs(x = "Date", y = paste("Average", value_column), title = paste("Average", value_column, "with Confidence Interval")) +
theme_minimal()+
scale_x_date(date_breaks = if (show_all_years) "1 year" else "5 years", date_labels = "%Y")
}
add_season_column <- function(data, month_column='month') {
data <- data %>%
mutate(season = case_when(
!!sym(month_column) %in% 1:3 ~ '(I) Winter',   # January to March
!!sym(month_column) %in% 4:6 ~ '(II) Spring',   # April to June
!!sym(month_column) %in% 7:9 ~ '(III) Summer',   # July to September
!!sym(month_column) %in% 10:12 ~ '(IV) Fall'  # October to December
))
data$season <- as.factor(data$season)
return(data)
}
seasonal_boxplot <- function(data_boxplot, y_var, y_lab){
result <- ggplot(data_boxplot, aes(x = season, y = !!sym(y_var))) +
geom_boxplot() +
labs(x = "", y = y_lab) +
ggtitle("")+ theme_minimal()
return(result)
}
# ================= End of the funcitons
# mapping data
map_2019 <- st_read('/Users/babak.jfard/projects/Datasets/maps/cb_2019_us_county_20m/cb_2019_us_county_20m.shp') %>%
select(GEOID, NAME)
map_2019$GEOID <- as.integer(as.character(map_2019$GEOID))
PM25_counties <- read_csv( '/Users/babak.jfard/projects/Health_Airpollution/data/processed/all_PM25.csv') %>% mutate(GEOID = as.integer(GEOID))
PM25_counties$ month <- as.numeric(PM25_counties$month)
# Drought data
drought_gws<- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/CSV_gws/gws_combined.csv'
drought_rtzsm <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/CSV_rtzsm/rtzsm_combined.csv'
drought_sfsm <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/CSV_sfsm/sfsm_combined.csv'
drought_dsci <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/DSCI.csv'
droughts <- list()
drought_gws <- read_csv(drought_gws) %>% mutate(GEOID=as.integer(GEOID)) %>%
mutate(year = year(time), month=month(time))%>% select(-time)
drought_gws <- drought_gws %>% mutate(min = mean - 1* sd) # A remedy. Will remove later
GEOIDs <- unique(drought_gws$GEOID)
drought_rtzsm <- read_csv(drought_rtzsm) %>% mutate(GEOID=as.integer(GEOID)) %>%
mutate(year = year(time), month=month(time))%>% select(-time)
drought_rtzsm <- drought_rtzsm %>% mutate(min = mean - 1* sd) # A remedy. Will remove later
drought_sfsm <- read_csv(drought_sfsm) %>% mutate(GEOID=as.integer(GEOID)) %>%
mutate(year = year(time), month=month(time))%>% select(-time)
drought_sfsm <- drought_sfsm %>% mutate(min = mean - 1* sd) # A remedy. Will remove later
drought_dsci <- read_csv(drought_dsci)%>% mutate(GEOID=as.integer(GEOID)) %>%
filter(GEOID %in% GEOIDs)
droughts<- list(gws=drought_gws, rtzsm=drought_rtzsm, sfsm= drought_sfsm, dsci = drought_dsci)
#drought <- bind_rows(drought_1, drought_2) %>% mutate(year = year(time), month=month(time))%>%
#  select(-time)
drought_plots <- list()
map_2019 <- map_2019 %>% filter(GEOID %in% GEOIDs)
# highest for drought
highest_droughts <- list()
for (drought_type in 1:(length(droughts)-1)){
drought <- droughts[[drought_type]]
drought_var <- names(droughts)[drought_type]
drought <- drought %>% filter(year %in% 2002:2018)
highest_drought <- highest_averaged_values(drought, 'max', n=310, highest = TRUE)%>%
rename_with(~drought_var, average)
highest_droughts[[drought_var]] <- highest_drought
drought_map <- map_of_available_values(map_2019, highest_drought, drought_var, fill_low = 'green',fill_high = 'brown')
drought_plots[[drought_var]] <- drought_map
}
highest_PM25 <- highest_averaged_values((PM25_counties %>% filter(year %in% 2002:2018)), 'PM25_max', n=310) %>%
rename(PM25=average)
# Now PM25
PM25_map <- map_of_available_values(map_2019, highest_PM25, 'PM25', )
#grid.arrange(PM25_map, drought_map)
combined_plot <- do.call(grid.arrange, c(list(PM25_map), drought_plots))
drought_gws<- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/CSV_gws/gws_combined.csv'
drought_rtzsm <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/CSV_rtzsm/rtzsm_combined.csv'
drought_sfsm <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/CSV_sfsm/sfsm_combined.csv'
drought_dsci <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/DSCI.csv'
droughts <- list()
drought_gws <- read_csv(drought_gws) %>% mutate(GEOID=as.integer(GEOID)) %>%
mutate(year = year(time), month=month(time))%>% select(-time)
drought_gws <- drought_gws %>% mutate(min = mean - 1* sd) # A remedy. Will remove later
GEOIDs <- unique(drought_gws$GEOID)
drought_rtzsm <- read_csv(drought_rtzsm) %>% mutate(GEOID=as.integer(GEOID)) %>%
mutate(year = year(time), month=month(time))%>% select(-time)
drought_rtzsm <- drought_rtzsm %>% mutate(min = mean - 1* sd) # A remedy. Will remove later
drought_sfsm <- read_csv(drought_sfsm) %>% mutate(GEOID=as.integer(GEOID)) %>%
mutate(year = year(time), month=month(time))%>% select(-time)
drought_sfsm <- drought_sfsm %>% mutate(min = mean - 1* sd) # A remedy. Will remove later
drought_dsci <- read_csv(drought_dsci)%>% mutate(GEOID=as.integer(GEOID)) %>%
filter(GEOID %in% GEOIDs)
droughts<- list(gws=drought_gws, rtzsm=drought_rtzsm, sfsm= drought_sfsm, dsci = drought_dsci)
#drought <- bind_rows(drought_1, drought_2) %>% mutate(year = year(time), month=month(time))%>%
#  select(-time)
drought_plots <- list()
map_2019 <- map_2019 %>% filter(GEOID %in% GEOIDs)
# highest for drought
highest_droughts <- list()
for (drought_type in 1:(length(droughts)-1)){
drought <- droughts[[drought_type]]
drought_var <- names(droughts)[drought_type]
drought <- drought %>% filter(year %in% 2002:2018)
highest_drought <- highest_averaged_values(drought, 'max', n=310, highest = TRUE)%>%
rename_with(~drought_var, average)
highest_droughts[[drought_var]] <- highest_drought
drought_map <- map_of_available_values(map_2019, highest_drought, drought_var, fill_low = 'green',fill_high = 'brown')
drought_plots[[drought_var]] <- drought_map
}
highest_PM25 <- highest_averaged_values((PM25_counties %>% filter(year %in% 2002:2018)), 'PM25_max', n=310) %>%
rename(PM25=average)
# Now PM25
PM25_map <- map_of_available_values(map_2019, highest_PM25, 'PM25', )
#grid.arrange(PM25_map, drought_map)
combined_plot <- do.call(grid.arrange, c(list(PM25_map), drought_plots))
# =====================================================================================
# ************************************************************ May 24, 2023 Babak J.Fard
# Creating local Moran's I maps for each year from 2002 to 2018 and adding them into
# an sliding map (only for PM2.5 and DSCI)
rm(list = ls())
library(rgeoda)
library(ggplot2)
library(gganimate)
LISA_map_ggplot <- function(data_column, title="LISA results"){
weight_matrix <- queen_weights(sf_obj = data_column)
lisa <- local_moran(weight_matrix, data_column, permutations = 9999, cpu_threads = 8)
lisa_colors <- lisa_colors(lisa)
lisa_labels <- lisa_labels(lisa)
lisa_clusters <- lisa_clusters(lisa)
#print(lisa_colors)
#print(lisa_labels)
# print(lisa_clusters)
year <- names(data_column)[1]
data_column[year] <- as.factor(lisa_clusters)
# map_test['lisa_p'] <- as.factor(lisa_pvalues(lisa))
result <- ggplot(data = data_column)+
geom_sf(aes(fill=!!sym(year)), size=0.2, color="grey")+
scale_fill_manual(values = lisa_colors, labels=lisa_labels)+
geom_sf(data=state_map, fill=NA, size=0.3, color='black')+
theme_void()+
labs(title = title)+
theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5))
theme(plot.background = element_rect(fill = "white"))
return(result)
}
std_map_ggplot <- function(data_column, title="std map"){
sd_dev_colors <- c("#3566A6", "#76A8CB", "#D4E4EF", "#F7DCC9", "#E18E6A", "#A32A30")
year <- names(data_column)[2]
map_test <- merge(map_2019, data_column, by='GEOID')
#map_test[as.character(year)] <- dat
# map_test['lisa_p'] <- as.factor(lisa_pvalues(lisa))
result <- ggplot(data = map_test)+
geom_sf(aes(fill=!!sym(year)), size=0.2, color="grey")+
scale_fill_manual(values = sd_dev_colors)+
geom_sf(data=state_map, fill=NA, size=0.2, color='black')+
theme_void()+
labs(title = title)+
theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5))
theme(plot.background = element_rect(fill = "white"))
return(result)
}
std_cuts <- function(data_column){
st_dev <- stddev_breaks(data_column)
data <- unlist(data_column)
# Create the factor column with custom levels
categories <- factor(cut(data, breaks = c(-Inf, st_dev, Inf)))
return(categories)
}
tibble_to_cut_std <- function(to_std){
to_std <- to_std%>% ungroup()
done_std <-tibble(GEOID= to_std$GEOID)
to_std <- to_std %>% select(-c(GEOID, NAME))
for (col in colnames(to_std)){
done_std[col] <- std_cuts(to_std[col])
}
return(done_std)
}
# Prepare your data and create a list of ggplot objects
# Assuming you have a list of ggplot objects named gg_list
PNGs_from_ggplot_list <- function(gg_list, output_folder){
# Set the output directory where the BMP images will be saved
output_directory <- output_folder
# Create the output directory if it doesn't exist
# dir.create(output_directory, showWarnings = FALSE, recursive = TRUE)
# Loop through the ggplot objects and save each frame as a BMP image
for (i in seq_along(gg_list)) {
# Set the output file name for the current frame
output_file <- paste0(output_directory, "/frame_", sprintf("%03d", i), ".bmp")
# Save the current frame as a BMP image
ggsave(filename = output_file, plot = gg_list[[i]], device = "png", dpi = 300, bg = "white")
}
}
PM25_counties <- read_csv( '/Users/babak.jfard/projects/Health_Airpollution/data/processed/all_PM25.csv') %>% mutate(GEOID = as.integer(GEOID))
PM25_counties$ month <- as.numeric(PM25_counties$month)
GEOIDs <- unique(PM25_counties$GEOID)
map_2019 <- st_read('/Users/babak.jfard/projects/Datasets/maps/cb_2019_us_county_20m/cb_2019_us_county_20m.shp') %>%
select(GEOID, NAME)
map_2019$GEOID <- as.integer(as.character(map_2019$GEOID))
map_2019 <- map_2019 %>% filter(GEOID %in% GEOIDs)
state_map <- st_read('/Users/babak.jfard/Documents/ArcGIS/cb_2018_us_state_20m_CONUS/cb_2018_us_state_20m.shp')
drought_dsci <- '/Users/babak.jfard/projects/NASA_Drought/Data/processed/DSCI.csv'
drought_dsci <- read_csv(drought_dsci)%>% mutate(GEOID=as.integer(GEOID)) %>%
filter(GEOID %in% GEOIDs)
# Create the time maps for PM25 and DSCI
PM25_annual <- PM25_counties %>% group_by(GEOID, year)%>%
summarise(averaged_max=mean(PM25_max)) %>%
pivot_wider(names_from = year, values_from = averaged_max)
PM25_annual <- merge(map_2019, PM25_annual, by='GEOID')
DSCI_annual <- drought_dsci %>% group_by(GEOID, year)%>%
summarise(averaged_max=mean(max)) %>%
pivot_wider(names_from = year, values_from = averaged_max)
DSCI_annual <- merge(map_2019, DSCI_annual, by='GEOID')
View(PM25_annual)
PM25_std <- tibble_to_cut_std(st_drop_geometry(PM25_annual[3:21]))
std_map_ggplot <- function(data_column, title="std map"){
sd_dev_colors <- c("#3566A6", "#76A8CB", "#D4E4EF", "#F7DCC9", "#E18E6A", "#A32A30")
year <- names(data_column)[2]
map_test <- merge(map_2019, data_column, by='GEOID')
#map_test[as.character(year)] <- dat
# map_test['lisa_p'] <- as.factor(lisa_pvalues(lisa))
result <- ggplot(data = map_test)+
geom_sf(aes(fill=!!sym(year)), size=0.2, color="grey")+
scale_fill_manual(values = sd_dev_colors)+
geom_sf(data=state_map, fill=NA, size=0.2, color='black')+
theme_void()+
labs(title = title)+
theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.5))
theme(plot.background = element_rect(fill = "white"))
return(result)
}
std_cuts <- function(data_column){
st_dev <- stddev_breaks(data_column)
data <- unlist(data_column)
# Create the factor column with custom levels
categories <- factor(cut(data, breaks = c(-Inf, st_dev, Inf)))
return(categories)
}
tibble_to_cut_std <- function(to_std){
to_std <- to_std%>% ungroup()
done_std <-tibble(GEOID= to_std$GEOID)
to_std <- to_std %>% select(-c(GEOID, NAME))
for (col in colnames(to_std)){
done_std[col] <- std_cuts(to_std[col])
}
return(done_std)
}
# Prepare your data and create a list of ggplot objects
# Assuming you have a list of ggplot objects named gg_list
PNGs_from_ggplot_list <- function(gg_list, output_folder){
# Set the output directory where the BMP images will be saved
output_directory <- output_folder
# Create the output directory if it doesn't exist
# dir.create(output_directory, showWarnings = FALSE, recursive = TRUE)
# Loop through the ggplot objects and save each frame as a BMP image
for (i in seq_along(gg_list)) {
# Set the output file name for the current frame
output_file <- paste0(output_directory, "/frame_", sprintf("%03d", i), ".bmp")
# Save the current frame as a BMP image
ggsave(filename = output_file, plot = gg_list[[i]], device = "png", dpi = 300, bg = "white")
}
}
View(DSCI_annual)
View(PM25_annual)
# Create the time maps for PM25 and DSCI
PM25_annual <- PM25_counties %>% group_by(GEOID, year)%>%
summarise(averaged_max=mean(PM25_max)) %>%
pivot_wider(names_from = year, values_from = averaged_max)
PM25_annual <- merge(map_2019, PM25_annual, by='GEOID')
DSCI_annual <- drought_dsci %>% group_by(GEOID, year)%>%
summarise(averaged_max=mean(max)) %>%
pivot_wider(names_from = year, values_from = averaged_max)
DSCI_annual <- merge(map_2019, DSCI_annual, by='GEOID')
PM25_std <- tibble_to_cut_std(st_drop_geometry(PM25_annual))
View(PM25_std)
DSCI_std <- tibble_to_cut_std(st_drop_geometry(DSCI_annual))
std_map_ggplot(data_column = PM25_std[,7], title = 'PM25')
std_map_ggplot(data_column = PM25_std[,c(1,7)], title = 'PM25')
std_map_ggplot(data_column = PM25_std[,c(1,18)], title = 'PM25')
View(PM25_std)
dim(PM25_std)[2]
ggplots_std_PM25 <- lapply(2:dim(PM25_std)[2],
function(x) std_map_ggplot(data_column =
PM25_std[,c(1,x)], title = 'PM25'))
ggplots_std_PM25[[19]]
ggplots_std_DSCI <- lapply(2:dim(DSCI_std)[2],
function(x) std_map_ggplot(data_column =
DSCI_std[,c(1,x)], title = 'DSCI'))
# Now Creating the BMPs
PNGs_from_ggplot_list(gg_list = ggplots_std_PM25, output_folder = '/Users/babak.jfard/projects/NASA_Drought/Data/plots/PM25_std_animate')
PNGs_from_ggplot_list(gg_list = ggplots_std_DSCI, output_folder = '/Users/babak.jfard/projects/NASA_Drought/Data/plots/DSCI_std_animate' )
library(tidyverse)
mort <- read_csv(/Users/babak.jfard/windows_Files/structure/intel_core_i5/data/raw/USA_reduced_csv/health_['2000'].csv)
mort <- read_csv('/Users/babak.jfard/windows_Files/structure/intel_core_i5/data/raw/USA_reduced_csv/health_['2000'].csv')
mort <- read_csv('/Users/babak.jfard/windows_Files/structure/intel_core_i5/data/raw/USA_reduced_csv/health_1999.csv')
View(mort)
names(mort)
library(tidyverse)
mort <- read_csv('/Users/babak.jfard/windows_Files/structure/intel_core_i5/data/interim/for_Raheleh/health_['2003'].csv')
mort <- read_csv('/Users/babak.jfard/windows_Files/structure/intel_core_i5/data/interim/for_Raheleh/health_2003.csv')
mort <- read_csv('/Users/babak.jfard/windows_Files/structure/intel_core_i5/data/interim/for_Raheleh/health_2003.csv')
View(mort)
colnames(mort)
colnames(mort)
dim(mort)
source("~/projects/ETHTracking/codes/R/functions_Drinking_Water_2023.R")
source("~/projects/ETHTracking/codes/R/summarize_Drinking_Water_2023.R")
# Disclaimer
# This code was written for the prepartation of the Water Summary product for
# CDC Tracking Spring 2023 Data Call. All responsibilities for using this code is
# upon the user.
rm(list = ls()) # clear the memory
library(rtf)
print("We suggest to run the validation test before this step.")
source('codes/R/functions_Drinking_Water_2023.R') # Getting required functions
setwd('/Users/babak.jfard/projects/ETHTracking')
source("~/projects/ETHTracking/codes/R/summarize_Drinking_Water_2023.R")
View(annual_max)
source("~/projects/ETHTracking/codes/R/summarize_Drinking_Water_2023.R")
