{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth Defects for Nebraska - EPHTracking Fall 2024 Data Call\n",
    "- Babak J.Fard -- October 2024\n",
    "\n",
    "This notebook shows the steps in creating the Birth Defects (BD) datasets-as required by the Tracking How-To-Guide (HTG) and Data Dictionary- from the raw datasets. Since the format of the raw dataset maybe very specific and different from other states (even from the future BD datasets) no separate python code (.py file) is created. The user is suggested to consider the potential differences and changes for use with other datasets. The notebook is reorganized into four sections to be easy to follow.\n",
    "\n",
    "* All cell outputs that may contain detailed level health data are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries for data validation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from libraries import general as ge\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/babak.jfard/projects/EPHTracking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing the Birth Defects Data\n",
    "This year, the provided data were in the final format, including nine columns of the required finalized columns to submit. In the last data submission cycle (2023), we had received the raw birth defects data. The process are available in `Birth_Defects_2023.ipynb`. To make sure that the provided birth defects values match with the last year data for the common years (2005 to 2021), we compared our finalized birth defects data with the data we received. The steps are in `Birth_Defects_2024_vs_2023.ipynb`.\n",
    "\n",
    "Below, we just calculate the two columns of `LBWBD` and `LBFDTWD` following the How-to-Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the provided .XLSX files into one dataframe\n",
    "\n",
    "# Directory containing the .xlsx files\n",
    "# folder_path = 'Data/BirthDefects_09192024'\n",
    "folder_path = 'Data/BirthDefects_09192024/final'\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.xlsx'):  \n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Try to read the .xlsx file\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=0)  # Read the first sheet\n",
    "            data_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "bd_2024 = pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total births with a detected birth defect for each group\n",
    "group_by = ['BirthDefect', 'County', 'StartDate', 'EndDate','MaternalAgeGroup', 'MaternalEthnicity', 'MaternalRace',\n",
    "                   'InfantSex']\n",
    "\n",
    "bd_2024_final = bd_2024.groupby(group_by, as_index=False).agg(LBWBD=('LiveBirth', lambda x: (x == 'Y').sum()),\n",
    "                                           LBFDTWD=('LiveBirth', 'size')).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the finalized birth defects file\n",
    "bd_2024_final.to_csv('Data/BirthDefects_09192024/Birth_Dfects_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Preparing the Live Birth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing ages into MaternalAgeGroup\n",
    "# Categorizing maternal age into the groups from Birth Defects Dictionary, May 2022\n",
    "def categorize_age(df, age_col = 'Mom_Age', new_col= 'MaternalAgeGroup'):\n",
    "    # Define the age categorization function\n",
    "    def age_category(age):\n",
    "        if age < 20:\n",
    "            return 1\n",
    "        elif 20 <= age <= 24:\n",
    "            return 2\n",
    "        elif 25 <= age <= 29:\n",
    "            return 3\n",
    "        elif 30 <= age <= 34:\n",
    "            return 4\n",
    "        elif 35 <= age <= 39:\n",
    "            return 5\n",
    "        elif age >= 40:\n",
    "            return 6\n",
    "        else:\n",
    "            return 9  # Unknown\n",
    "\n",
    "    # Apply the age categorization function to the 'Mom_Age' column\n",
    "    df[new_col] = df[age_col].apply(age_category)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from libraries import general as ge\n",
    "\n",
    "# from itables import init_notebook_mode\n",
    "\n",
    "#init_notebook_mode(all_interactive=True)\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/babak.jfard/projects/EPHTracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live_births = pd.read_csv('Data/BIRTHDEFECTS080823/Live Births/bth2005.csv')\n",
    "folder = r'Data/Live_Births_09192024'\n",
    "live_births = pd.concat((pd.read_csv(folder+'/'+filename)) for filename in os.listdir(folder) if filename.endswith('.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of live births in each year\")\n",
    "live_births.DOB_YY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those with mother state of residence as NE\n",
    "live_births = live_births[live_births.strm == 'NE'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all counties covered?\n",
    "live_births['coures'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting the FIPS code, Maternal Ethnicity, and Dates\n",
    "received FIPS codes for the counties are in three digit format. needs to be chanded into five digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making FIPS codes into 5 dgigts\n",
    "state_FIPS = '31' #For Nebraska.\n",
    "\n",
    "live_births.coures = live_births.coures.astype('str').str.zfill(3) #Pad strings in the Series/Index by prepending ‘0’ characters.\n",
    "live_births['County'] = (state_FIPS+ live_births['coures']).astype('int')\n",
    "live_births.drop(columns='coures', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births['StartDate'] = live_births['DOB_YY'].astype('str') + '0101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.rename(columns={'sex': 'InfantSex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinguishing Ethnicity\n",
    "# Define the conditions and choices\n",
    "conditions = [\n",
    "    live_births['hispanicm'].str.contains('H'),\n",
    "    live_births['hispanicm'].str.contains('U')\n",
    "]\n",
    "choices = ['H', 'U']\n",
    "\n",
    "# Create the new column using np.select\n",
    "live_births['MaternalEthnicity'] = np.select(conditions, choices, default='NH')\n",
    "live_births = live_births.drop(columns='hispanicm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.MaternalEthnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing maternal age into the groups from the HTG, and saving it into the appropriate column\n",
    "live_births = categorize_age(live_births, age_col='agemo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing Maternal Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_other_columns = ['aindianm', 'chamorrom', 'chinesem', 'filipinom', 'indianm', 'japanesem',\n",
    "                      'koreanm', 'nhawaiianm', 'opacislm', 'otheram', 'otherm', 'samoanm', 'vietnamesem']\n",
    "race_black_columns = 'blackm'\n",
    "race_white_columns = 'whitem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the unique values in all other race columns are 'Y' or 'N'\n",
    "[print(f\"{col}: {live_births[col].value_counts(dropna=False)}\") for col in race_other_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing to digist to better be able to check consistency\n",
    "to_digits = {'Y':1, 'N':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[live_births[col].replace(to_digits, inplace=True) for col in race_other_columns]\n",
    "live_births[race_other_columns] = live_births[race_other_columns].replace(to_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating all into one column for other\n",
    "live_births['race_other'] = live_births[race_other_columns].sum(axis=1)\n",
    "live_births['race_other'] = np.where(live_births['race_other']>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for Black and White races\n",
    "live_births[race_white_columns].replace(to_digits, inplace=True)\n",
    "live_births[race_black_columns].replace(to_digits, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking potential values. In an ideal situation there must be only one\n",
    "# or 0 for unknown\n",
    "three_races = ['blackm', 'whitem', 'race_other']\n",
    "live_births[three_races].sum(axis=1).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well. Looks good. only about 3% are not 1. Now if this value is other than one it will return 'U', otherwise checks which of 'W', 'B' or 'O' applies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the three columns\n",
    "live_births['sum_race'] = live_births[['blackm', 'whitem', 'race_other']].sum(axis=1)\n",
    "\n",
    "# Define the conditions and choices for the 'MaternalRace' column\n",
    "conditions = [\n",
    "    (live_births['sum_race'] != 1),\n",
    "    (live_births['blackm'] == 1),\n",
    "    (live_births['whitem'] == 1),\n",
    "    (live_births['race_other'] == 1)\n",
    "]\n",
    "choices = ['U', 'B', 'W', 'O']\n",
    "\n",
    "# Create the 'MaternalRace' column using numpy.select\n",
    "live_births['MaternalRace'] = np.select(conditions, choices, default='U')\n",
    "\n",
    "# Drop the 'sum_race' column as it's no longer needed\n",
    "live_births.drop('sum_race', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.MaternalRace.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up\n",
    "Here we prepare, rename and reorder column to get ready for joining with the birth defects data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['County', 'StartDate', 'MaternalAgeGroup', 'MaternalEthnicity', 'MaternalRace',\n",
    "                   'InfantSex']\n",
    "live_births = live_births[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.StartDate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_births.to_csv('Data/BirthDefects_09192024/live_births_cleaned_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now grouping them and calculating TLB\n",
    "#live_births['TLB'] = live_births.groupby(columns_to_keep).transform('size')\n",
    "lb_grouped = live_births.groupby(columns_to_keep).agg(TLB=('County', 'size')).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_grouped.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Total births\n",
    "lb_grouped.to_csv('Data/BirthDefects_09192024/live_births_summarized_2.csv', index=False)\n",
    "\n",
    "# ****************************** F I N I S H E D (Live Birth data section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Joining the Datasets\n",
    "Here we join the two tables into the final table. But first check to make sure that the key columns actually match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from libraries import general as ge\n",
    "\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/babak.jfard/projects/EPHTracking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_grouped = pd.read_csv('Data/BirthDefects_09192024/Birth_Dfects_2024.csv')\n",
    "lb_grouped = pd.read_csv('Data/BirthDefects_09192024/live_births_2024_summarized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the years have all 93 counties\n",
    "lb_grouped.groupby('StartDate')['County'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key columns to join the live birth and birth defects tables\n",
    "key_cols = ['County', 'StartDate', 'MaternalAgeGroup', 'MaternalEthnicity', 'MaternalRace', 'InfantSex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bd_grouped.dtypes)\n",
    "print(lb_grouped.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_grouped['County'] = lb_grouped['County'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the unique values of key columns in each df befor joining them\n",
    "def comp_col_types(lb_grouped, bd_grouped, key_cols):\n",
    "    lb_cols = lb_grouped[key_cols].dtypes.to_list()\n",
    "    bd_cols = bd_grouped[key_cols].dtypes.to_list()\n",
    "\n",
    "    if lb_cols == bd_cols:\n",
    "        print(\"Columns match. We're good to go!\")\n",
    "    else:\n",
    "        print(\"There are some mismatches between key columns\")\n",
    "        print(key_cols)\n",
    "        print(f\"Birth Defects: {bd_cols}\")\n",
    "        print(f\"Live Births: {lb_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_col_types(lb_grouped, bd_grouped, key_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the differences in the unique values for corresponding columns\n",
    "for col in key_cols:\n",
    "    values_bd = set(bd_grouped[col])\n",
    "    values_lb = set(lb_grouped[col])\n",
    "    \n",
    "    unique_to_bd = values_bd - values_lb\n",
    "    unique_to_lb = values_lb - values_bd\n",
    "    \n",
    "    print(f\"Values in {col} unique to Birth Defects: {unique_to_bd}\")\n",
    "    print(f\"Values in {col} unique to Live Births: {unique_to_lb}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer join between Birth Defects and Live Births\n",
    "We will have all counties present in each year. But LBWBD and LBFDTWD values for many cases will be 0 because there is no Birth Defect in such cases. It will require an outer join method. Also, each birth defect when added for TLBs must add up into total live births. Therefore, we separate BD data for each BirthDefect, do outer join and in the end concatenate all the resulted 12 tables into one final table\n",
    "\n",
    "***Note:*** to make sure that the denominator for each Birth Defect is the total live birth, data for each birth defect is separated and is outer joined with the live birth data, and in the end all the separate 12 joined tables are concatenated into the final dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two datasets\n",
    "all_bds = []  # Create an empty list to store the dataframes\n",
    "\n",
    "# Loop over unique values of 'BirthDefects' column in bd_grouped\n",
    "for defect in bd_grouped['BirthDefect'].unique():\n",
    "    # Separate rows with the current 'BirthDefects' value\n",
    "    current_defect_df = bd_grouped[bd_grouped['BirthDefect'] == defect]\n",
    "    \n",
    "    # Perform the outer join with lb_grouped on key columns\n",
    "    merged_df = lb_grouped.merge(current_defect_df, on=key_cols, how='outer')\n",
    "    \n",
    "    # For unassigned 'BirthDefects', change them to the current 'BirthDefect' value\n",
    "    merged_df['BirthDefect'] = merged_df['BirthDefect'].fillna(defect)\n",
    "    \n",
    "    # Add the new dataframe to the 'all_bds' list\n",
    "    all_bds.append(merged_df)\n",
    "\n",
    "# Continue the loop for the next 'BirthDefect'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd = pd.concat(all_bds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next step will be to take care of Nan values for non-matched rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_bd.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) TLB: TLB is for those cases that we have maternal age 9. This is exactly the same number as we had in the first approach. Therefore we set them to -999\n",
    "2) BirthDefect: For cases that we only want to provide live births. We add 21\n",
    "3) EndDate = (StartDate // 1e4)* 1e4 + 1231\n",
    "4) LBWBD will be 0 for all missing values\n",
    "5) LBFDTWD same as LBWBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bd['TLB'] = final_bd['TLB'].fillna(-999).astype('int')\n",
    "final_bd['EndDate'] = ((final_bd['StartDate'] // 1e4) * 1e4 + 1231).astype('int')\n",
    "final_bd['LBWBD'] = (final_bd['LBWBD'].fillna(0)).astype('int')\n",
    "final_bd['LBFDTWD'] = (final_bd['LBFDTWD'].fillna(0)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toSave = final_bd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: Prepare Data to Save\n",
    "This is the final step to save data into format and numbers that can be submitted to the Tracking system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the columns in the same order as Data Dictionary\n",
    "ordered_columns = ['County', 'StartDate', 'EndDate', 'BirthDefect', 'MaternalAgeGroup',\n",
    "                   'MaternalEthnicity', 'MaternalRace', 'InfantSex', 'TLB', 'LBWBD', 'LBFDTWD']\n",
    "\n",
    "data_toSave = data_toSave[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types\n",
    "data_toSave.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_toSave['InfantSex'] = data_toSave['InfantSex'].replace({'N': 'U'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check\n",
    "for i in range(8):\n",
    "    col = data_toSave.columns[i]\n",
    "    print(f'Column: {col}')\n",
    "    print(data_toSave[col].unique())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now saving each year into a separate file:\n",
    "#output_folder = 'Data/BIRTHDEFECTS080823/To_Submit/'\n",
    "output_folder = 'Data/BirthDefects_09192024/final_submit_2/'\n",
    "\n",
    "for st_date in data_toSave.StartDate.unique():\n",
    "    to_save = data_toSave[data_toSave['StartDate'] == st_date]\n",
    "    to_save.index = range(1, len(to_save) + 1)\n",
    "    year = (st_date//1e4).astype('int').astype('str')\n",
    "    filename = output_folder+'BirthDefects_AllCounties_'+year+ '.csv'\n",
    "\n",
    "    to_save.to_csv(filename, index = True,index_label='RowIdentifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Some Checks\n",
    "Some checks to make sure the data makes sense\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking if the sum of TLBs for each BirthDefect adds up to total live births in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ignore_values(series, ignore=-999):\n",
    "    return series.replace(ignore, np.nan).sum()\n",
    "\n",
    "print(data_toSave.pivot_table(index='StartDate', columns='BirthDefect', values='TLB', aggfunc=lambda x: sum_ignore_values(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plotting the Sum, max, mean, min for each Birth Defect in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_summaries(df, groups, coexist, x_column, nrow):\n",
    "    # Get unique values from the groups column\n",
    "    unique_groups = df[groups].unique()\n",
    "    \n",
    "    # Calculate number of columns for the grid\n",
    "    ncol = len(unique_groups) // nrow\n",
    "    if len(unique_groups) % nrow != 0:\n",
    "        ncol += 1\n",
    "    \n",
    "    # Initialize a figure\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(15, 10))\n",
    "    \n",
    "    # If there's only one row or one column, axes is a 1D array\n",
    "    if nrow == 1 or ncol == 1:\n",
    "        axes = axes.reshape(nrow, ncol)\n",
    "    \n",
    "    # Iterate over each unique group and plot\n",
    "    for idx, group in enumerate(unique_groups):\n",
    "        ax = axes[idx // ncol, idx % ncol]\n",
    "        \n",
    "        # Filter dataframe for the current group\n",
    "        subset = df[df[groups] == group]\n",
    "        \n",
    "        # Plot each column in coexist\n",
    "        for col in coexist:\n",
    "            sns.lineplot(data=subset, x=x_column, y=col, ax=ax, label=col)\n",
    "        \n",
    "        ax.set_title(f\"{groups}: {group}\")\n",
    "        ax.legend()\n",
    "    \n",
    "    # If there are empty subplots, hide them\n",
    "    for idx in range(len(unique_groups), nrow * ncol):\n",
    "        axes[idx // ncol, idx % ncol].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_summary = data_toSave.groupby(['BirthDefect', 'StartDate'])['LBFDTWD'].agg(SUM = 'sum', MIN='min', MEAN='mean', MAX='max').reset_index()\n",
    "ds_summary['BirthDefect'] = ds_summary['BirthDefect'].astype('int')\n",
    "ds_summary.StartDate = ds_summary.StartDate.astype('str').str[2:4]\n",
    "\n",
    "plot_summaries(df=ds_summary, groups='BirthDefect', coexist=['SUM', 'MIN', 'MEAN', 'MAX'], x_column='StartDate', nrow=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
